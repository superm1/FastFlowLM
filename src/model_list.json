{
    "model_path": "models",
    "models": {
 	    "gemma3": {
            "270m": {
                "name": "Gemma3-270M-NPU2",
                "url": "https://huggingface.co/FastFlowLM/Gemma3-270M-NPU2",
                "modified_at": "2025-05-30T00:00:00Z",
                "size": 270000000,
                "default_context_length": 32768,
		        "flm_min_version": "0.9.4",
                "files":[
                    "attn.xclbin",
                    "config.json",
                    "dequant.xclbin",
                    "layer.xclbin",
                    "lm_head.xclbin",
                    "mm.xclbin",
                    "model.q4nx",
                    "tokenizer.json",
                    "tokenizer_config.json"
                ],
                "details": {
                    "format": "NPU2",
                    "family": "gemma3",
                    "think": false,
                    "think_toggleable": false,
                    "parameter_size": "270M",
                    "quantization_level": "Q4_1"
                }
            },

            "1b": {
                "name": "Gemma3-1B-NPU2",
                "url": "https://huggingface.co/FastFlowLM/Gemma3-1B-NPU2",
                "modified_at": "2025-05-30T00:00:00Z",
                "size": 1000000000,
                "default_context_length": 32768,
		        "flm_min_version": "0.9.4",
                "files":[
                    "attn.xclbin",
                    "config.json",
                    "dequant.xclbin",
                    "layer.xclbin",
                    "lm_head.xclbin",
                    "mm.xclbin",
                    "model.q4nx",
                    "tokenizer.json",
                    "tokenizer_config.json"
                ],
                "details": {
                    "format": "NPU2",
                    "family": "gemma3",
                    "think": false,
                    "think_toggleable": false,
                    "parameter_size": "1B",
                    "quantization_level": "Q4_1"
                }
            },
            "4b": {
                "name": "Gemma3-4B-NPU2",
                "url": "https://huggingface.co/FastFlowLM/Gemma3-4B-NPU2",
                "modified_at": "2025-05-30T00:00:00Z",
                "size": 4000000000,
                "default_context_length": 65536,
		        "flm_min_version": "0.9.11",
                "vlm": true,
                "files":[
                    "attn.xclbin",
                    "config.json",
                    "dequant.xclbin",
                    "layer.xclbin",
                    "lm_head.xclbin",
                    "mm.xclbin",
                    "model.q4nx",
                    "tokenizer.json",
                    "tokenizer_config.json",
                    "vision_attn.xclbin",
                    "vision_mm.xclbin",
                    "vision_weight.q4nx"
                ],
                "details": {
                    "format": "NPU2",
                    "family": "gemma3",
                    "think": false,
                    "think_toggleable": false,
                    "parameter_size": "4B",
                    "quantization_level": "Q4_1"
                }
            }
        },
        "medgemma":{
            "4b": {
                "name": "Medgemma-4B-NPU2",
                "url": "https://huggingface.co/FastFlowLM/medgemma-4b-it-NPU2",
                "modified_at": "2025-05-30T00:00:00Z",
                "size": 4000000000,
                "default_context_length": 65536,
                "vlm": true,
		        "flm_min_version": "0.9.11",
                "files":[
                    "attn.xclbin",
                    "config.json",
                    "dequant.xclbin",
                    "layer.xclbin",
                    "lm_head.xclbin",
                    "mm.xclbin",
                    "model.q4nx",
                    "tokenizer.json",
                    "tokenizer_config.json",
                    "vision_attn.xclbin",
                    "vision_mm.xclbin",
                    "vision_weight.q4nx"
                ],
                "details": {
                    "format": "NPU2",
                    "family": "gemma3_text",
                    "think": false,
                    "think_toggleable": false,
                    "parameter_size": "4B",
                    "quantization_level": "Q4_1"
                }
            }
        },
        "llama3.2": {
            "1b": {
                "name": "Llama-3.2-1B-NPU2",
                "url": "https://huggingface.co/FastFlowLM/Llama-3.2-1B-NPU2",
                "modified_at": "2025-05-30T00:00:00Z",
                "size": 1000000000,
                "flm_min_version": "0.1.8",
                "default_context_length": 131072,
                "files":[
                    "attn.xclbin",
                    "config.json",
                    "dequant.xclbin",
                    "layer.xclbin",
                    "lm_head.xclbin",
                    "mm.xclbin",
                    "model.q4nx",
                    "tokenizer.json",
                    "tokenizer_config.json"
                ],
                "details": {
                    "format": "NPU2",
                    "family": "llama",
                    "think": false,
                    "parameter_size": "1B",
                    "quantization_level": "AWQ-asym-uint4-g32"
                }
            },
            "3b": {
                "name": "Llama-3.2-3B-NPU2",
                "url": "https://huggingface.co/FastFlowLM/Llama-3.2-3B-NPU2",
                "modified_at": "2025-05-30T00:00:00Z",
                "size": 3000000000,
                "flm_min_version": "0.1.8",
                "files":[
                    "attn.xclbin",
                    "config.json",
                    "dequant.xclbin",
                    "layer.xclbin",
                    "lm_head.xclbin",
                    "mm.xclbin",
                    "model.q4nx",
                    "tokenizer.json",
                    "tokenizer_config.json"
                ],
                "default_context_length": 65536,
                "details": {
                    "format": "NPU2",
                    "family": "llama",
                    "think": false,
                    "parameter_size": "3B",
                    "quantization_level": "AWQ-asym-uint4-g32"
                }
            }
        },
        "llama3.1": {
            "8b": {
                "name": "Llama-3.1-8B-NPU2",
                "url": "https://huggingface.co/FastFlowLM/Llama-3.1-8B-NPU2",
                "modified_at": "2025-05-30T00:00:00Z",
                "size": 8000000000,
                "flm_min_version": "0.1.8",
                "files":[
                    "attn.xclbin",
                    "config.json",
                    "dequant.xclbin",
                    "layer.xclbin",
                    "lm_head.xclbin",
                    "mm.xclbin",
                    "model.q4nx",
                    "tokenizer.json",
                    "tokenizer_config.json"
                ],
                "default_context_length": 16384,
                "details": {
                    "format": "NPU2",
                    "family": "llama",
                    "think": false,
                    "parameter_size": "8B",
                    "quantization_level": "AWQ-asym-uint4-g32"
                }
            }
        },
        "deepseek-r1": {
            "8b": {
                "name": "Deepseek-R1-Distill-Llama-8B-NPU2",
                "url": "https://huggingface.co/FastFlowLM/Deepseek-R1-Distill-Llama-8B-NPU2",
                "modified_at": "2025-05-30T00:00:00Z",
                "size": 8000000000,
                "flm_min_version": "0.1.8",
                "files":[
                    "attn.xclbin",
                    "config.json",
                    "dequant.xclbin",
                    "layer.xclbin",
                    "lm_head.xclbin",
                    "mm.xclbin",
                    "model.q4nx",
                    "tokenizer.json",
                    "tokenizer_config.json"
                ],
                "default_context_length": 16384,
                "details": {
                    "format": "NPU2",
                    "family": "llama",
                    "think": true,
                    "parameter_size": "8B",
                    "quantization_level": "AWQ-asym-uint4-g32"
                }
            }
        },
        "deepseek-r1-0528": {
            "8b": {
                "name": "DeepSeek-R1-0528-Qwen3-8B-NPU2",
                "url": "https://huggingface.co/FastFlowLM/DeepSeek-R1-0528-Qwen3-8B-NPU2",
                "modified_at": "2025-05-30T00:00:00Z",
                "size": 8000000000,
                "flm_min_version": "0.9.6",
                "files":[
                    "attn.xclbin",
                    "config.json",
                    "dequant.xclbin",
                    "layer.xclbin",
                    "lm_head.xclbin",
                    "mm.xclbin",
                    "model.q4nx",
                    "tokenizer.json",
                    "tokenizer_config.json"
                ],
                "default_context_length": 16384,
                "details": {
                    "format": "NPU2",
                    "family": "qwen3",
                    "think": true,
                    "think_toggleable": false,
                    "parameter_size": "8B",
                    "quantization_level": "Q4_1"
                }
            }
        },
        "qwen3": {
            "0.6b": {
                "name": "Qwen3-0.6B-NPU2",
                "url": "https://huggingface.co/FastFlowLM/Qwen3-0.6B-NPU2",
                "modified_at": "2025-05-30T00:00:00Z",
                "size": 600000000,
                "flm_min_version": "0.9.3",
                "files":[
                    "attn.xclbin",
                    "config.json",
                    "dequant.xclbin",
                    "layer.xclbin",
                    "lm_head.xclbin",
                    "mm.xclbin",
                    "model.q4nx",
                    "tokenizer.json",
                    "tokenizer_config.json"
                ],
                "default_context_length": 32768,
                "details": {
                    "format": "NPU2",
                    "family": "qwen",
                    "think": true,
                    "think_toggleable": true,
                    "parameter_size": "0.6B",
                    "quantization_level": "Q4_1"
                }
            },
            "1.7b": {
                "name": "Qwen3-1.7B-NPU2",
                "url": "https://huggingface.co/FastFlowLM/Qwen3-1.7B-NPU2",
                "modified_at": "2025-05-30T00:00:00Z",
                "size": 1700000000,
                "flm_min_version": "0.9.3",
                "files":[
                    "attn.xclbin",
                    "config.json",
                    "dequant.xclbin",
                    "layer.xclbin",
                    "lm_head.xclbin",
                    "mm.xclbin",
                    "model.q4nx",
                    "tokenizer.json",
                    "tokenizer_config.json"
                ],
                "default_context_length": 32768,
                "details": {
                    "format": "NPU2",
                    "family": "qwen",
                    "think": true,
                    "think_toggleable": true,
                    "parameter_size": "1.7B",
                    "quantization_level": "Q4_1"
                }
            },
            "4b": {
                "name": "Qwen3-4B-NPU2",
                "url": "https://huggingface.co/FastFlowLM/Qwen3-4B-NPU2",
                "modified_at": "2025-05-30T00:00:00Z",
                "size": 4000000000,
                "flm_min_version": "0.9.3",
                "files":[
                    "attn.xclbin",
                    "config.json",
                    "dequant.xclbin",
                    "layer.xclbin",
                    "lm_head.xclbin",
                    "mm.xclbin",
                    "model.q4nx",
                    "tokenizer.json",
                    "tokenizer_config.json"
                ],
                "default_context_length": 32768,
                "details": {
                    "format": "NPU2",
                    "family": "qwen",
                    "think": true,
                    "think_toggleable": true,
                    "parameter_size": "4B",
                    "quantization_level": "AWQ-asym-uint4-g32"
                }
            },
            "8b": {
                "name": "Qwen3-8B-NPU2",
                "url": "https://huggingface.co/FastFlowLM/Qwen3-8B-NPU2",
                "modified_at": "2025-05-30T00:00:00Z",
                "size": 8000000000,
                "flm_min_version": "0.9.3",
                "files":[
                    "attn.xclbin",
                    "config.json",
                    "dequant.xclbin",
                    "layer.xclbin",
                    "lm_head.xclbin",
                    "mm.xclbin",
                    "model.q4nx",
                    "tokenizer.json",
                    "tokenizer_config.json"
                ],
                "default_context_length": 16384,
                "details": {
                    "format": "NPU2",
                    "family": "qwen",
                    "think": true,
                    "think_toggleable": true,
                    "parameter_size": "8B",
                    "quantization_level": "AWQ-asym-uint4-g32"
                }
            }
        },
        "qwen3-tk": {
            "4b": {
                "name": "Qwen3-4B-Thinking-2507-NPU2",
                "url": "https://huggingface.co/FastFlowLM/Qwen3-4B-Thinking-2507-NPU2",
                "modified_at": "2025-05-30T00:00:00Z",
                "size": 4000000000,
                "flm_min_version": "0.9.6",
                "files":[
                    "attn.xclbin",
                    "config.json",
                    "dequant.xclbin",
                    "layer.xclbin",
                    "lm_head.xclbin",
                    "mm.xclbin",
                    "model.q4nx",
                    "tokenizer.json",
                    "tokenizer_config.json"
                ],
                "default_context_length": 32768,
                "details": {
                    "format": "NPU2",
                    "family": "qwen",
                    "think": true,
                    "think_toggleable": false,
                    "parameter_size": "4B",
                    "quantization_level": "Q4_1"
                }
            }
        },
        "qwen3-it": {
            "4b": {
                "name": "Qwen3-4B-Instruct-2507-NPU2",
                "url": "https://huggingface.co/FastFlowLM/Qwen3-4B-Instruct-2507-NPU2",
                "modified_at": "2025-05-30T00:00:00Z",
                "size": 4000000000,
                "flm_min_version": "0.9.6",
                "files":[
                    "attn.xclbin",
                    "config.json",
                    "dequant.xclbin",
                    "layer.xclbin",
                    "lm_head.xclbin",
                    "mm.xclbin",
                    "model.q4nx",
                    "tokenizer.json",
                    "tokenizer_config.json"
                ],
                "default_context_length": 32768,
                "details": {
                    "format": "NPU2",
                    "family": "qwen",
                    "think": false,
                    "think_toggleable": false,
                    "parameter_size": "4B",
                    "quantization_level": "Q4_1"
                }
            }
        },
        "gpt-oss": {
            "20b": {
                "name": "GPT-OSS-20B-NPU2",
                "url": "https://huggingface.co/FastFlowLM/GPT-OSS-20B-NPU2",
                "modified_at": "2025-05-30T00:00:00Z",
                "size": 20000000000,
                "flm_min_version": "0.9.12",
                "files":[
                    "attn.xclbin",
                    "config.json",
                    "dequant_mxfp4.xclbin",
                    "dequant_q4_1.xclbin",
                    "expert.xclbin",
                    "layer.xclbin",
                    "lm_head.xclbin",
                    "mm.xclbin",
                    "model.q4nx",
                    "tokenizer.json",
                    "tokenizer_config.json"
                ],
                "default_context_length": 8192,
                "details": {
                    "format": "NPU2",
                    "family": "gpt-oss",
                    "think": true,
                    "think_toggleable": false,
                    "parameter_size": "4B",
                    "quantization_level": "Q4_1"
                }
            }
        }
    }

}
