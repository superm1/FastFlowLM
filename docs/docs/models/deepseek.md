---
layout: docs
title: Deepseek
nav_order: 2
parent: Models
---

## üß© Model Card: [DeepSeek-R1-Distill-Llama-8B](https://huggingface.co/deepseek-ai/DeepSeek-R1-Distill-Llama-8B)

- **Type:** Text-to-Text
- **Think:** Yes
- **Tool Calling Support:** No  
- **Base Model:** [deepseek-ai/DeepSeek-R1-Distill-Llama-8B](https://huggingface.co/deepseek-ai/DeepSeek-R1-Distill-Llama-8B)
- **Quantization:** Q4_1
- **Max Context Length:** 128k tokens  
- **Default Context Length:** 16k tokens ([change default](https://fastflowlm.com/docs/instructions/cli/#-change-default-context-length-max))  
- **[Set Context Length at Launch](https://fastflowlm.com/docs/instructions/cli/#-set-context-length-at-launch)**

‚ñ∂Ô∏è Run with FastFlowLM in PowerShell:  

```shell
flm run deepseek-r1:8b
```

---

## üß© Model Card: [DeepSeek-R1-0528-Qwen3-8B](https://huggingface.co/deepseek-ai/DeepSeek-R1-0528-Qwen3-8B)

- **Type:** Text-to-Text
- **Think:** Yes
- **Tool Calling Support:** No  
- **Base Model:** [deepseek-ai/DeepSeek-R1-0528-Qwen3-8B](https://huggingface.co/deepseek-ai/DeepSeek-R1-0528-Qwen3-8B)
- **Quantization:** Q4_1
- **Max Context Length:** 64k tokens  
- **Default Context Length:** 16k tokens ([change default](https://fastflowlm.com/docs/instructions/cli/#-change-default-context-length-max))  
- **[Set Context Length at Launch](https://fastflowlm.com/docs/instructions/cli/#-set-context-length-at-launch)**

‚ñ∂Ô∏è Run with FastFlowLM in PowerShell:  

```shell
flm run deepseek-r1-0528:8b
```