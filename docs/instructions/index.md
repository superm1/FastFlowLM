---
title: Instructions
nav_order: 2
has_children: true
---

# üõ†Ô∏è Instructions

**FastFlowLM (FLM)** is a deeply optimized runtime for **local LLM inference on AMD NPUs** ‚Äî  
ultra-fast, power-efficient, and 100% offline.

Its user interface and workflow are similar to **Ollama**, but purpose-built for AMD's XDNA architecture.

This section will walk you through how to use FastFlowLM with examples. 